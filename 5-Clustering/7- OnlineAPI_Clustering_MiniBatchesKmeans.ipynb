{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Online learning of a dictionary of parts of faces\n",
    "==================================================\n",
    "\n",
    "This example uses a large dataset of faces to learn a set of 20 x 20\n",
    "images patches that constitute faces.\n",
    "\n",
    "From the programming standpoint, it is interesting because it shows how\n",
    "to use the online API of the scikit-learn to process a very large\n",
    "dataset by chunks. The way we proceed is that we load an image at a time\n",
    "and extract randomly 50 patches from this image. Once we have accumulated\n",
    "500 of these patches (using 10 images), we run the `partial_fit` method\n",
    "of the online KMeans object, MiniBatchKMeans.\n",
    "\n",
    "The verbose setting on the MiniBatchKMeans enables us to see that some\n",
    "clusters are reassigned during the successive calls to\n",
    "partial-fit. This is because the number of patches that they represent\n",
    "has become too low, and it is better to choose a random new\n",
    "cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "# Load the Olivetti faces data-set from AT&T (classification). 10 images of each of the 40 classes\n",
    "# returns data, images, target, DESCR\n",
    "# data: numpy array of shape (400, 4096) Each row corresponds to a ravelled face image of original size 64 x 64 pixels. \n",
    "# images: numpy array of shape (400, 64, 64) Each row is a face image corresponding to one of the 40 subjects of the dataset.\n",
    "# target : numpy array of shape (400, ) Labels associated to each face image. Those labels are ranging from 0-39 and correspond to the Subject IDs\n",
    "faces = datasets.fetch_olivetti_faces()\n",
    "\n",
    "#print(\"length of faces.images\", len(faces.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0) #exposes a number of methods for generating random numbers\n",
    "kmeans = MiniBatchKMeans(n_clusters=81, random_state=rng, verbose=True)\n",
    "\n",
    "help(MiniBatchKMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Learn the dictionary of images\n",
    "\n",
    "print('Learning the dictionary... ')\n",
    "\n",
    "patch_size = (20, 20)\n",
    "\n",
    "buffer = []\n",
    "t0 = time.time()\n",
    "\n",
    "# The online learning part: cycle over the whole dataset 6 times,\n",
    "index = 0\n",
    "for _ in range(6):\n",
    "    for img in faces.images:\n",
    "        #Reshape a 2D image into a collection of patches\n",
    "        data = extract_patches_2d(img, patch_size, max_patches=50, random_state=rng) \n",
    "        #print(\"data shape\",data.shape)\n",
    "        \n",
    "        data = np.reshape(data, (len(data), -1)) #len(data)= max_patches,  -1. the value is inferred from the length of the array and remaining dimensions.\n",
    "        #print(\"data shape\",data.shape)\n",
    "        buffer.append(data)\n",
    "        index += 1\n",
    "        if index % 10 == 0:\n",
    "            data = np.concatenate(buffer, axis=0)\n",
    "            data -= np.mean(data, axis=0)\n",
    "            data /= np.std(data, axis=0)\n",
    "            kmeans.partial_fit(data) #Update k means estimate on a single mini-batch X.\n",
    "            buffer = []\n",
    "        if index % 100 == 0:\n",
    "            print('Partial fit of %4i out of %i'\n",
    "                  % (index, 6 * len(faces.images)))\n",
    "\n",
    "dt = time.time() - t0\n",
    "print('done in %.2fs.' % dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot the results\n",
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, patch in enumerate(kmeans.cluster_centers_):\n",
    "    plt.subplot(9, 9, i + 1)\n",
    "    plt.imshow(patch.reshape(patch_size), cmap=plt.cm.gray, interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "plt.suptitle('Patches of faces\\nTrain time %.1fs on %d patches' % (dt, 8 * len(faces.images)), fontsize=16)\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
